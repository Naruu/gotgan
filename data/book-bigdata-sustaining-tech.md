# 데이터 파이프라인

- 데이터 파이프라인: 데이터를 차례대로 전달해나가는 시스템. 데이터 수집 -> 적재 -> 추출 -> 가공 -> 활용
- 워크플로우 관리: 데이터 파이프라인의 동작을 관리하는 것.

  - 수집
    - 여러 장소에서 발생한 여러 형태의 데이터를 모음
    - 데이터 전송
      - bulk: 이미 어딘가에 존재하는 데이터를 정리해 추출. 데이터베이스와 파일 서버 등에서 정기적으로 데이터 전송
      - streaming: 계속해서 생성되는 데이터를 끊임없이 보내는 방법. 모바일 앱, 임베디드 장비 등
  - 처리
    - batch
    - stream: 실시간 처리

- 데이터 웨어하우스와 데이터 마트

  - 데이터 웨어하우스는 대량의 데이터를 장기보관하는 목적.
  - 소량의 데이터를 자주 꺼내서 읽는 것은 적합하지 않음. 따라서 분석을 위해서는 데이터 웨어하우스에서 필요한 데이터만 추출하여 데이터 마트를 구축함.
  - 데이터가 생성되는 `데이터 소스`에서 `원시 데이터(raw data)`를 추출하고 가공하여 데이터 웨어하우스에 넣는 과정을 ETL(Extract Transform Load)라고 한다
  - 테이블 설계가 먼저 필요함.

- 데이터 레이크

  - 데이터를 원래 형태로 축적하는 저장소
  - 여러 곳에서 데이터가 흘러들어오는 것을 비유.
  - 데이터 형식이 자유로움. csv, json이 대부분.

- 애드혹 분석: 일회성 분석
- 데이터 수집의 목적

  - 데이터 검색: 대량의 데이터 중 조건에 맞는 것을 찾음. ex) 로그에서 장애 원인 분석
  - 데이터 가공: 업무 시스템의 일부로 데이터 처리 결과를 이용. ex) 구매한 상품을 기반으로 상품 추천
  - 시각화: 데이터를 시각화하여 의사 결정에 참고.

- 확증적 분석과 탐색적 분석

  - 가설을 세우고 검증하는 것: 확증적 분석
  - 데이터를 살펴보고 의미를 읽어내는 것: 탐색적 분석

- 수작업 vs 자동화

## 빅데이터의 탐색

- 크로스 집계
  - 크로스 테이블: 행과 열이 카테고리인 테이블
  - 트랜잭션 테이블: 행 방향으로 데이터가 증가하는 테이블.
  - 트랜잭션 테이블을 크로스 테이블로 변환하는 것: 크로스 집계
  - 피벗 테이블: 집계(aggregtion) 작업을 한 크로스 테이블
- 데이터의 지연(latency) 줄이기
  - 압축과 분산
  - MPP(massive parallel processing): 멀티 코어를 활용하면서 디스크 I/O를 병렬처리하는 아키텍처
- 열 지향 스토리지
  - 행 지향 데이터베이스: 데이터를 행 단위로 저장. 데이처 추가가 빠름. 인덱스를 통해 데이터 검색 고속화
  - 열 지향 데이터베이스: 데이터를 열 단위로 저장. 데이터 분석시 일부 열만 이용하기 때문에, 로드하는 데이터 양을 줄일 수 있다. 압축 효율도 높음.
    유사한 데이터나 같은 문자열이 반복될 때 압축률이 높다.
  - 열 지향 데이터 베이스, MPP
- 데이터 마트의 기본 구조
  - 트랜잭션: 시간과 함께 생성되는 데이터를 기록한 것. 한번 기록되면 변하지 않는다.
  - 마스터: 트랜젝션에서 참고되는 정보. 상황에 따라 다시 쓰인다.
  - 팩트 테이블: 트랜잭션처럼 사실이 기록된 것
  - 디멘션 테이블: 팩트 테이블을 참고할때 사용하는 마스터 데이터.
  - ex) 상품별 12월 판매 실적: 트랜젝션, 상품 이름, 금액 등의 상품 정보: 마스터
  - 데이터 마트는 비정규화 테이블로 구성하는 것이 단순하고 효율적.

## 분산 처리

- 분산처리 프레임워크

  - 데이터의 종류
    - 스키마: 테이블의 칼럼 명, 데이터형, 테이블 간의 관계 등을 정의한 것.
    - 구조화 데이터: 스키마가 명확히 정의된 데이터
    - 비구조화 데이터: 스키마가 없는 데이터
    - 스키마리스 데이터(반구조화 데이터): 기본 형식은 정해져있지만, 칼럼 수나 데이터 형이 명확하지 않은 데이터. ex) csv, json, xml
  - 데이터 처리를 위한 프레임워크
    - hadoop
      - 분산 파일 시스템: HDFS(Hadoop Distributed File System)
      - 리소스 관리자: YARN(Yet Another Resource Negotiator)
        - CPU, 메모리 등을 컨테이너라는 단위로 관리. Docker Container와 다름. job 요청을 받으면 비어있는 호스트에 컨테이너 할당.
      - 분산 데이터 처리: MapReduce(java), Hive(query engine), Impala(query engine), Presto(query engine)
        - MapReduce, Hive는 배치 처리에는 적합하나 adhoc에는 적합하지 않음.
        - Hive를 가속화하기 위해 Hive on Tez 개발
        - Impala, Presto: 대화형 쿼리 엔진
        - hadoop 위의 쿼리엔진: SQL-on-Hadoop이라 부름
      - 다른 조합으로도 이용 가능. ex) Mesos, Spark
    - spark
      - in-memory 데이터 처리.
      - MapReduce, Tez는 데이터 처리 과정에서 생성되는 중간 데이터를 모두 디스크에 읽고 써서 느렸다.
      - Spark SQL, Spark Streaming 존재. 하나의 프레임워크로 모두 처리 가능.

- 데이터 마트의 구축
  - 팩트 테이블
    - 테이블에 데이터를 추가 또는 치환한다.
    - 추가의 경우
      - 추가에 실패한 것을 모른다면, 데이터를 잃는다.
      - 중복해서 추가될 수 있다
      - 팩트 테이블을 재생성할 때, 관리가 복잡하다
    - table partitioning
      - 하나의 테이블을 여러 물리 파티션으로 나누어 파티션 단위로 데이터를 쓰고 삭제하는 것
      - 1일 1회, 1시간 1회 등 주기적으로 새 파티션을 만들고 파티션을 교체한다.
    - 치환은 시간이 오래걸리므로 소요 시간과 실행 주기를 주의해야 한다.
  - 집계 테이블
    - 팩트 테이블을 모아서 집계한 테이블(summary table)
    - 각 칼럼이 가질 수 있는 값의 범위: cardinality \
      ex) 성별: 남, 여, 모름 -> 3, ip 주소 -> 높은 cardinality
  - snapshot table, historical table
    - 마스터 데이터처럼 업데이트 되는 테이블을 관리하는 2가지 방법
      - snapshot table: 정기적으로 테이블 통째로 저장
      - historical table: 변경 내용만 저장

## 축적

- 객체 스토리지
  - 데이터를 객체로 취급하는 저장 방법
  - 읽기쓰기는 네트워크를 거침. 여러 디스크에 복사하여 저장.
  - 대량의 데이터에는 효율적이나 소량은 비효율적.
- bulk: ETL. 전통적인 데이터웨어하우스에서 사용하는 방법. 이미 축적된 데이터를 이용하는 경우
- streaming: 지금 바로 생성되는 데이터를 이용하는 경우. ex) 웹 브라우저, 휴대폰, 센서 등의 디바이스의 데이터 수집 \
  다수의 클라이언트에서 작은 데이터가 계속 전송됨 이것을 메시지 배송(message delivery)라고 한다.
  모바일: MBaaS(Mobile Backend as a Service), 디바이스: MTQQ(MQ Telemetry Transport) 등을 사용하기도 함.
- 메시지 브로커

  - 대량의 메시지를 안정적으로 받기 위한 중간 스토리지
  - 너무 자주 쓰는 것을 막고, 외부의 메세지 양을 조절하기 위함.
  - push형, pull형, producer, consumer
    - push형: 송신 측이 주도권
    - pull형: 수신 측이 주도권
    - producer(생산자): 메시지 브로커에 데이터를 넣는 쪽(push)
    - consumer(소비자): 메시지 브로커에서 데이터를 가져오는 쪽(pull)
      > 사진: https://developer.ibm.com/articles/advantages-of-an-event-driven-architecture/
  - 메시지 라우팅: 메시지 브로커에 써넣은 데이터는 복사되어 여러 소비자에서 읽어 올 수 있다.
  - 신뢰성 문제

    - 네트워크에서는 메시지 중복/누락이 발생하기 쉽다
    - at most once
      - 무슨 일이 일어나도 재전송하지 않는다
    - exactly once
      - 송신과 수신 측 양쪽에 coordinator가 존재하여 서로 정보가 전달됨을 보장한다
      - 문제1. coordinator가 장애로 정지할 수 있다 -> 합의(consensus)가 필요하다.
      - 문제2. coordinator의 개입으로 성능이 저하된다.
    - at least once
      - 보통 사용되는 방식
      - 재전송에도 문제가 없도록 중복을 제거한다
      - TCP/IP가 at least once 방식. 프로토콜에서 자동으로 중복을 제거함
      - 메시지 배송에서는 이용자가 구현해야함.
    - 중복 제거

      - 중복 제거는 비싸다
      - offset을 이용한 중복제거
        - 전송하는 데이터에 offset을 실어서 전송
        - 중복 전달되어도 동일한 위치에 쓰여지기 때문에 중복이 제거됨
        - 벌크 전송에 적합. streaming에는 적합 X
      - 고유 id를 이용한 중복 제거
        - streaming 전송에서 이용
        - 모든 메세지에 uuid 등의 고유 ID를 지정.
        - 최근에 받은 id만 기억하고 이전 데이터는 중복 허용.
        - 데이터를 처리하는 최종 말단에서 중복 제거 처리

      > 사진 설명

      - 클라이언트: 메시지가 생성되는 기기
      - 프론트 엔드: 메시지를 먼저 받는 서버

  - 시계열 데이터(Time Series)

    - 프로세스 시간과 이벤트 시간

      - 프로세스 시간: 서버에서 처음 데이터가 확인된 시간
      - 이벤트 시간: 클라이언트에서 메시지가 생성된 시간
      - 데이터 분석에서 주된 관심사는 이벤트 시간이다.
      - 클라이언트의 데이터는 서버에 늦게 도착할 수 있다
      - 늦게 도착한 데이터를 위해 과거의 모든 파일에서 검색하는 것은 비효율적이다. \
        모든 파일에서 검색하는 것을 full scan이라 한다.
      - 이벤트 시간 집계를 위한 효율화
        - 시계열 인덱스: 이벤트 시간으로 인덱스를 생성. cassandra 등 지원. \
          짧은 범위의 시간을 빠르게 집계하는데에는 유용하나 대량 데이터에는 비효율적.
        - 조건절 푸시다운(predicate pushdown)
          - 열 지향 스토리지는 칼럼마다 통계 정보(최솟값, 최댓값 등)을 담고 있다.
            이 메타 데이터 이용하여 원하는 데이터의 위치를 효율적으로 파악할 수 있다. \
            이 정보를 이용하여 필요한 최소한의 데이터를 읽도록 하는 최적화를 predicate pushdown이라 한다.
      - 이벤트 시간에 대한 검색 효율화
        - 시간 정보로 table partitioning: 시계열 테이블
        - 데이터 마트만 이벤트 시간으로 정렬

    - NoSQL
      - 애플리케이션에서 처음으로 데이터를 기록하는 장소로 이용. \
        분석을 위해서는 다른 툴을 연동하는 것이 일반적. \
        RDB보다 읽기 성능이 좋다.
      - 분산 KVS
        - 모든 데이터를 key-value 쌍으로 저장
        - 객체 스토리지도 넓은 의미에서 분산 KVS의 일종이지만, 여기서는 좀 더 작은 데이터를 의미함. \
          몇 KB를 수만번 읽고 쓰는 정도
        - 모든 데이터에 고유의 키를 부여하고 키로 데이터를 저장할 노드 결정.
        - ex) Amaonzon DynanmoDB
      - 와이드 칼럼 스토어
        - 2개 이상의 키에 데이터를 저장할 수 있도록 한 것.
        - ex) Google Cloud BigTable, Apahce HNase, Apache Cassandra
        - 내부적으로 행 키 + 칼럼 명의 조합에 대해 값을 저장
        - 칼럼을 쉽게 추가할 수 있는 구조
          > https://www.researchgate.net/figure/Data-layout-in-wide-column-stores_fig1_264859776
      - 도큐먼트 스토어
        - json 같은 스키마리스 데이터 처리가 주 목적
        - ex) mongoDB
      - 검색 엔진
        - 저장된 데이터를 쿼리로 찾아낸다.
        - 역 색인(inverted index)를 생성한다.
        - ex) Elastic Search, Splunk

## 파이프라인

- 워크플로우 관리 도구

  - 역할
    - 태스크를 스케줄에 따라 실행하고 결과 통지
    - 태스크 간의 의존 관계를 정리하고, 순서대로 실행
    - 태스크의 실행 결과를 보관하고, 오류시 재실행
  - 오류 처리
    - 재시도
    - 백필(backfill): 파라미터에 포함된 일자를 바꿔가면서 일정 기간의 태스크를 연속적으로 실행하는 것.
  - 테스크의 요건
    - 원자성 작업
      - 1개의 테스크는 1개의 변경을 일으키도록 구성한다. \
        테스크 실행 실패시, 부분적 변경이 일어나지 않아야한다.
      - 원자성을 지닌 추가: 중간 테이블에서 데이터를 수정하고, 최종 한번만 실제 테이블에 추가한다.
    - 멱등한 조작: 추가, 치환
      - 추가는 멱등적이지 않다.
      - 데이터 업데이트마다 치환하는 것은 부하가 크다
      - 테이블을 파티셔닝하여 주기적으로 파티션을 치환한다.
  - 태스크 큐
    - 한번에 너무 많은 태스크를 실행하면 부하 발생.
    - 외부 시스템의 요청 수만큼 태스크를 실행하는 대신, 일정 숫자만 병렬 실행 필요.
    - 태스크 큐(잡 큐)로 요청을 큐에 넣고 워커 프로세스가 꺼내서 실행하므로써 자원 소비량을 조절할 수 있다.

- 데이터플로우
  - 데이터플로우: 분산 시스템 내부에서의 데이터 처리. 워크플로우의 한 단계
  - 배치형
    - MapReduce
      - 더 이상 쓰지 않는다
      - 기본 개념: 데이터를 작은 단위(split)으로 나누어 처리하고(Map) 그 결과를 합친다.(Reduce)
    - DAG(Directed Acyclic Graph)로 태스크의 의존 관계 표현
  - 데이트 플로우와 워크 플로우 조합하기
    - 데이터 읽기
      - 데이터 소스에서 바로 데이터를 가져오지 않는다. 분산 스토리지에 복사하고 데이트 플로우에서 이용한다.
    - 데이터 쓰기(내보내기)
      - csv 등 취급하기 쉬운 파일로 분산 스토리지에 쓴다.
    - 데이터 웨어하우스 / 쿼리엔진을 이용한 데이터 마트
    - 대화식 분석
- 스트리밍형
  - 실시간형 데이터. ex) 시스템 모니터링, 로그 관리, 여러 시스템에서 온 이벤트 자동 처리
  - 배치와 스트리밍의 통합
    - 배치는 실행시 데이터 양이 정해지므로 유한 데이터(bounded data), \
      스트리밍은 제한이 없으므로 무한 데이터(unbounded data)라 한다
    - 스트리밍의 2가지 문제
      - 장애 등으로 결과가 잘못된 경우, 재실행 또는 과거의 데이터를 어떻게 수정할 수 있는가?
      - 늦게 온 데이터는 어떻게 처리하는가? 이벤트 시간과 프로세스 시간은 같지 않다.
    - 람다 아키텍처
      - 배치와 스트리밍 2개의 파이프라인
      - 배치 처리: 배치 레이어 + 서빙 레이어 \
        서빙 레이어의 결과물: 배치뷰
      - 스트리밍 처리: 스피드 레이어 \
        스피드 레이어의 결과물: 실시간 뷰
      - 스트리밍의 결과는 일시적으로만 사용하고, 신뢰할 수 있는 데이터는 배치 결과를 이용
        > https://docs.microsoft.com/en-us/azure/architecture/data-guide/big-data/
    - 카파 아키텍처
      - 람다 아키텍처는 2개의 레이어에서 같은 작업을 하므로 비효율적
      - 스피드레이어만 이용한다. 대신, 메시지 배송 시간을 조절한다. \
        문제가 발생하면 메시지를 재배송.
      - 문제점: 부하가 높아진다. 과거의 데이터까지 한번에 처리해야할 수도 있다.

## 분석 기반

- 스키마리스
  - 카디너리리티
- hadoop
- 워크 플로우 관리 도구
- 클라우드

## TODO

- https://www.oreilly.com/radar/the-world-beyond-batch-streaming-101/
- https://www.oreilly.com/radar/the-world-beyond-batch-streaming-102/
